{
    "contents" : "vb_model2_la_2<-function(formula, design_mats, alpha_0, beta_0, Sigma_alpha_0, Sigma_beta_0, LargeSample=TRUE, epsilon=1e-5)\n{\n  #Date: 10 September 2014\n  #Allan E Clark\n  #Multi-visit site occupancy model\n  #Estimation is undertaken using variational bayes and Laplace approximation\n  #----------------------------------------------------------------------------------\n  \n  #----------------------------------------------------------------------------------\n  #Arguments\n  #----------------------------------------------------------------------------------\n  #formula<- y~ occupancy covariates  ~ site detection covariates\n  #y <- n by J matrix of presence absence data\n  #n <- the number of locations\n  #J <- the number of visits to the sites\n  #Assumed that each site is visited J times\n  \n  #X <- a dataframe that contains the covariates used to calculate site occupancy probabilities\n  #W <- a named list that contains the site covariates used to calculate the site detection probabilities\n  #W has the same form as an unmarkedFrameOccu object in the unmarked package\n  \n  #alpha_0 <- starting value of detection covariate coefficients\n  #beta_0 <- starting value of occurence covariate coefficients \n  #Sigma_alpha_0, Sigma_beta_0 - the variance covariance matrix of alpha_0 and beta_0\n  #LargeSample<-TRUE - indicates that the number of sites is 'large' and that an \n  #approximation to B(mu, sigma^2) is used instead of integrations\n  #-----------------------------------------------------------------------------------\n  \n  #load the required functions\n  bx<-function(x){log(1+exp(x))}\n  \n  b1<-function(x)\n  {\n    #the first deriv of bx\n    1/(1+exp(-x))\n  }\n  \n  b2<-function(x)\n  {\n    #the second deriv of bx\n    exp(-x)/( (1+exp(-x))^2 )\n  }\n  \n  Ebx <- function(x, mu, sigma2)\n  {\n    #bx(mu+sigma*x)*dnorm(x)\n    argx<-mu+sqrt(sigma2)*x\n    log(1+exp(argx))*dnorm(x)\n  }\n  \n  B<-function(mu,sigma2)\n  {\n    #This does Brute force integrations\n    #Note that the range is limited to -2000 to 2000\n    integrate( Ebx, lower=-200, upper =200, mu=mu, sigma2=sigma2)$value\n  }\n  \n  B2<-function(mu, sigma2)\n  {\n    #Approximation to B(mu,sigma2) for large sample sizes\n    bx(mu)+b2(mu)*sigma2\n  }\n  \n  B0.approx <- function(mu,sigma2)\n  {\n    #John Ormerod code\n    sigma <- sqrt(sigma2)\n    vB0 <- mu*pnorm(mu/sigma) + sigma2*dnorm(mu,sd<-sigma)\n    vB0 <- vB0 + (0.6931472*exp(0.3298137*sigma2-0.8121745*mu))*pnorm( mu/sigma - 0.8121745*sigma)\n    vB0 <- vB0 + (0.6931472*exp(0.3298137*sigma2+0.8121745*mu))*pnorm(-mu/sigma - 0.8121745*sigma)\n    return(vB0)\n  }\n  \n  B1.approx <- function(mu,sigma2)\n  {\n    #John Ormerod code\n    sigma <- sqrt(sigma2)\n    muOnSigma <- mu/sigma\n    a1sigma <- 0.8121745*sigma\n    a1mu <- 0.8121745*mu\n    halfa1sqsigma2 <- 0.3298137*sigma2\n    vB1 <- pnorm(muOnSigma)\n    vB1 <- vB1 + 0.5629565*(exp(halfa1sqsigma2+a1mu)*pnorm(-muOnSigma - a1sigma) - exp(halfa1sqsigma2-a1mu)*pnorm( muOnSigma - a1sigma))\n    return(vB1)\n  }\n  \n  B2.approx <- function(mu,sigma2)\n  {\n    #John Ormerod code\n    sigma <- sqrt(sigma2)\n    muOnSigma <- mu/sigma\n    a1sigma <- 0.8121745*sigma\n    a1mu <- 0.8121745*mu\n    halfa1sqsigma2 <- 0.3298137*sigma2\n    vB2 <- -0.1259130*dnorm(mu,sd<-sigma)\n    vB2 <- vB2 + 0.4572189*((exp(halfa1sqsigma2-a1mu))*pnorm(muOnSigma - a1sigma) + (exp(halfa1sqsigma2+a1mu))*pnorm(-muOnSigma - a1sigma))\n    return(vB2)\n  }\n  \n  XWX.fun2 <- function(X,w) \n  {\n    #return( t(X)%*%diag(as.vector(w)))%*%X ) # Much slower\n    #return( t(X*as.vector(w))%*%X  )         # Much faster\n    return( crossprod(X*as.vector(w),X)  )    # faster than second version\n  }\n  \n  diagSet <- function(d) \n  {\n    #John Ormerod code\n    return(  d*((1:d)-1) + (1:d) )\n  }\n  \n  diagElements <- function(A) \n  {\n    #John Ormerod code\n    return( A[diagSet(nrow(A))] )\n  }\n  \n  trace <- function(A) \n  {\n    #John Ormerod code\n    #return(sum(diag(A)))          # Much slower\n    return(sum(diagElements(A)))  # Much faster \n  }\n  \n  X_row.Y_col=function(X,Y)\n  {\n    #does row by column matrix multiplication\n    #ie row_i of matrix X %*% column_j of matrix Y\n    #returns a column vector with the required elements\n    #appears faster than a simple loop\n    index=matrix(1:NROW(X))\n    matrix(apply(index,1,function(x, m1=X,m2=Y){m1[x,]%*%m2[,x]}))\n  }\n  \n  logp<-function(par, W, X, Y, P_tilde, p_tilde, p, alpha_0, SigmaInv_alpha_0, beta_0, SigmaInv_beta_0, Exp=0)\n  {\n    #log(q(alpha, beta)) when 'Exp<-0'\n    \n    ncol_W <- NCOL(W)\n    \n    alpha<- matrix(par[1:ncol_W], ncol=1)\n    beta<- matrix(par[-c(1:ncol_W)] , ncol=1)\n    \n    alpha_x<-W%*%alpha\n    alpha_diff <- alpha - alpha_0\n    beta_x<-X%*%beta\n    beta_diff <- beta - beta_0\n\n    t1 <- crossprod(Y,P_tilde)%*%alpha_x - crossprod(p_tilde,bx(alpha_x) ) + crossprod(p,beta_x) - sum( bx(beta_x) )\n    t2 <- 0.5*(1-Exp)*( crossprod(alpha_diff,SigmaInv_alpha_0)%*%alpha_diff + crossprod(beta_diff,SigmaInv_beta_0)%*%beta_diff  ) \n    \n    Logp <- t1[1]  - t2[1] \n    return(Logp)\n  }\n  \n  #----------------------------------------------------------------------------------\n  \n  #Declare certain matrices and constants\n  #---------------------------------------\n  #create a matrix where the elements of y are stored one vector below the other\n  #Y<-matrix(t(y), ncol=1) \n  #X<-as.matrix(X) #X stored as a matrix\n  \n  req_design_mats<-vb_ReqDesigns(formula, design_mats)\n  W<-req_design_mats$W\n  X<-req_design_mats$X\n  Y<-design_mats$Y\n  \n  n<-NROW(X)\n  N<-length(Y)\n  pn<-NCOL(X) #number of columns of X\n  qn<-NCOL(W) #number of columns of W\n\n#I am here now!\n\n  const1 <- (pn+qn)*(log(2*pi)+1)\n  const2<-determinant(Sigma_alpha_0, logarithm=T)$modulus[1] + determinant(Sigma_beta_0, logarithm=T)$modulus[1]\n  const3<- 0.5*(const1+const2)\n  \n  SigmaInv_alpha_0 <- chol2inv(chol(Sigma_alpha_0))\n  SigmaInv_beta_0 <- chol2inv(chol(Sigma_beta_0))\n  SigmaInv_times_alpha_0 <- SigmaInv_alpha_0%*%alpha_0\n  SigmaInv_times_beta_0 <- SigmaInv_beta_0%*%beta_0\n  #---------------------------------------\n  \n  #a matrix containing how many times each of the sites are visited\n  J<-dim(W)[2]\n  V<-matrix(rep(J),n)\n  \n  #create the W matrix\n  #Note that here were are assuming that V(i) are all equal\n  W_vb <- cbind(1,c(t(W[,,qn])))\n  \n  #the prior mean and covariance matrix of alpha and beta\n  #------------------------------------------------------\n  #the starting value for the alpha and beta vector (and covariance matrices)\n  #--------------------------------------------------------------------------\n  \n  alpha <- alpha_0*rnorm(1)  #some randomization\n  beta <- beta_0 *rnorm(1) #some randomization\n  Sigma_alpha <- Sigma_alpha_0 \n  Sigma_beta <- Sigma_beta_0 \n  Sigma_alpha_inv <-solve(Sigma_alpha_0)\n  Sigma_beta_inv <- solve(Sigma_beta_0)\n  \n  oldparams<- c(alpha, Sigma_alpha_inv, beta, Sigma_beta_inv)\n  nparams <- length(oldparams)\n  \n  #indentify which at which of the sites the species were observed!\n  #----------------------------------------------------------------\n  pres_abs <- apply(y,1,max)\n  obs_vec <- which(pres_abs==1) #where they were observed\n  not_obs_vec <- which(pres_abs==0) #where they were not observed\n  n_obs <- length(obs_vec)\n  n_not_obs <- length(not_obs_vec)\n  \n  #initial starting values of E(Z_tilde) and E(Z)\n  #----------------------------------------------\n  #if the species is observed at a site the element should be 1\n  p_tilde <- matrix(1, ncol=1, nrow=N)\n  p<-matrix(1, ncol=1, nrow=n)\n  \n  #the index of the location of the starting values of Z_tilde\n  #Z_tilde <- [(z1,z1,...z1),....,(zn,.......,zn)]^T\n  #only keep the ones where the species has not been observed\n  starts_z <- matrix(c(1+cumsum(V)-V)[not_obs_vec] , ncol=1)\n  Indices<-apply(starts_z,1,function(x,J.=J) x:(x+J.-1))\n  c_Indices<-c(Indices)\n  \n  t1<-apply(X[not_obs_vec,],1, function(x,beta.=beta){crossprod(x,beta.)}) \n  t2<-apply( matrix( bx(W_vb[c_Indices,]%*%alpha), nrow=n_not_obs , byrow=T) , 1, sum)   \n  p[not_obs_vec] <- 1/(1+ exp(-t1 + t2) ) \n  p_tilde[c_Indices]<-rep( p[not_obs_vec], each=J) \n  P_tilde<-diag(c(p_tilde))\n  \n  #Marginal likelihood approximation <- E(Log_p(y,z,alpha,beta))- E(q(alpha, beta, z))\n  #-----------------------------------------------------------------------------------  \n  Logp <- logp(c(alpha,beta), W=W_vb, X=X, Y=Y, P_tilde=P_tilde, p_tilde=p_tilde, p=p, alpha_0=alpha_0, SigmaInv_alpha_0=SigmaInv_alpha_0, beta_0=beta_0, SigmaInv_beta_0=SigmaInv_beta_0,Exp=1)\n  #Logp <- Logp -.5*( const1 + log(det(Sigma_alpha_0)) + log(det(Sigma_beta_0)) )  #E(Log_p(y,z,alpha,beta))\n  #Logp\n  Logp<-Logp -0.5*( const1 + determinant(Sigma_alpha_0, logarithm=T)$modulus[1] + determinant(Sigma_beta_0, logarithm=T)$modulus[1] )  #E(Log_p(y,z,alpha,beta))\n  #Logp\n  \n  #the E(q(alpha, beta, z)) part\n  #------------------------------\n  \n  #E_log_pz <- sum(p[not_obs_vec]*log(p[not_obs_vec]/(1-p[not_obs_vec])) + log(1-p[not_obs_vec])) #gave numerical errors sometimes\n  E_log_pz <-sum(log(p[not_obs_vec]^p[not_obs_vec]) + log( (1-p[not_obs_vec])^(1-p[not_obs_vec]) ))  \n  E_log_p_alpha_beta <- -0.5*( const1 + determinant(Sigma_alpha, logarithm=T)$modulus[1] + determinant(Sigma_beta, logarithm=T)$modulus[1] )\n  Log_ml <- Logp - E_log_p_alpha_beta[1] - E_log_pz\n    \n  #  cat(\"------------------------------------------------------------------------------------\",\"\\n\")\n  #  cat(\"STARTING VALUES\",\"\\n\")\n  #  cat(\"Log_ml <- \", Log_ml,\", alpha <- \", round(alpha,digits<-3) , \", beta <- \", round(beta,digits<-3), \"\\n\")\n  #  cat(\"------------------------------------------------------------------------------------\",\"\\n\")\n  \n  old_Log_ml<-Log_ml\n  \n  diff_Log_ml<-1\n  its<-0\n  \n  #epsilon <- 1e-10\n  \n  while (diff_Log_ml > epsilon)\n  {\n    its<-1+its\n    \n    #Perform the Newton Rhaphson algortihm to calculate alpha and beta at iteration t\n    #---------------------------------------------------------------------------------\n    #crit <- .5 #used to assess convergence of the parameters - Rule 1\n    crit<-0 #used for Rule 3\n    \n    #These are used in the Newton Rhaphson algortihm but don't change within the 'while' loop\n    g_alpha_1<- crossprod(W_vb, P_tilde%*%Y)\n    g_beta_1<- crossprod(X, p)\n    \n    while (crit < nparams) \n    {\n      alpha_x<-W_vb%*%alpha\n      g_alpha <- g_alpha_1 - crossprod(W_vb, p_tilde*b1(alpha_x)) - SigmaInv_alpha_0%*%alpha + SigmaInv_times_alpha_0\n      Sigma_alpha_inv <-   XWX.fun2(W_vb, p_tilde*b2(alpha_x)) + SigmaInv_alpha_0 #Note Sigma_alpha is not stored!\n      alpha <- alpha + solve(Sigma_alpha_inv,g_alpha)\n      \n      beta_x<-X%*%beta\n      g_beta <- g_beta_1 -crossprod(X, b1(beta_x)) - SigmaInv_beta_0%*%beta + SigmaInv_times_beta_0\n      Sigma_beta_inv <- XWX.fun2(X, b2(beta_x)) + SigmaInv_beta_0 #Note Sigma_beta is not stored!\n      beta <- beta + solve(Sigma_beta_inv, g_beta)\n  \n    #This section has not been fixed as yet\n    #------------------------------------------------------------------------------------------\n      #Stopping method 1\n      #-----------------\n      #       newparams<-c(alpha, Sigma_alpha, beta, Sigma_beta)\n      #       crit<-sum(abs(newparams-oldparams))\n      #       oldparams<-newparams\n      \n      #Stopping method 2 - this method will take longer in general!\n      #------------------------------------------------------------\n      #Logp <- logp(c(alpha,beta), W<-W_vb, X<-X, Y<-Y, P_tilde<-P_tilde, p_tilde<-p_tilde, p<-p, alpha_0<-alpha_0, SigmaInv_alpha_0<-SigmaInv_alpha_0, beta_0<-beta_0, SigmaInv_beta_0<-SigmaInv_beta_0, Exp<-0)\n      #E_log_p_alpha_beta <- -.5*( const1 + log(det(Sigma_alpha)) -log(det(Sigma_beta)) )    \n      #Log_ml <- Logp - E_log_p_alpha_beta[1] - E_log_pz\n      #crit <- abs(Log_ml-old_Log_ml)\n      #old_Log_ml <- Log_ml\n      \n      #Stopping method 3\n      #-----------------\n      #newparams<-c(alpha, Sigma_alpha, beta, Sigma_beta)\n      #crit<-sum(abs(newparams-oldparams) <= epsilon) #STRONG CONDITION!\n      #oldparams<-newparams  \n    #------------------------------------------------------------------------------------------\n    \n      #Stopping method 3\n      #-----------------\n      newparams<-c(alpha, Sigma_alpha_inv, beta, Sigma_beta_inv)\n      crit<-sum(abs(newparams-oldparams) <= epsilon) #STRONG CONDITION!\n      #print(crit)\n      oldparams<-newparams  \n    }\n    #Now we calculate the covariance matrices\n    Sigma_alpha<-solve(Sigma_alpha_inv)\n    Sigma_beta<-solve(Sigma_beta_inv)\n    \n    #Brute force maximisation\n    #starts_par<-c(alpha, beta)#*rnorm(1)\n    #starts_par<-c(Alpha, Beta)#*rnorm(1)\n    #fit1 <- optim(par<-starts_par, fn<-logq, W<-W_vb, X<-X, Y<-Y, P_tilde<-P_tilde, \n    #             p_tilde<-p_tilde, p<-p, alpha_0<-alpha_0, SigmaInv_alpha_0<-SigmaInv_alpha_0, beta_0<-beta_0, \n    #             SigmaInv_beta_0<-SigmaInv_beta_0, hessian<-T, control<-list(fnscale<--1), method<-\"BFGS\")\n    #fit1$par\n    #alpha <- matrix(fit1$par[1:2], ncol=1)\n    #beta <- matrix(fit1$par[3:4], ncol=1)\n    #Sigma_big <- solve(-fit1$hessian)\n    #Sigma_alpha <- Sigma_big[1:2,1:2]\n    #Sigma_beta <- Sigma_big[3:4, 3:4]\n    \n    #Calculate the occupancy probabilities at the different locations\n    #-----------------------------------------------------------------\n    #E_log_pz<-0\n\n    t1<-apply(X[not_obs_vec,],1, function(x,beta.=beta){crossprod(x,beta.)}) #correct (not_obs_vec by 1 vector)\n    #W_vb_sel<-W_vb[c_Indices,]\n    ag1<-W_vb[c_Indices,]%*%alpha\n    #ag2<-matrix(diag(W_vb_sel%*%Sigma_alpha%*%t(W_vb_sel)), ncol=1)\n    ag2<-X_row.Y_col(W_vb[c_Indices,],Sigma_alpha%*%t(W_vb[c_Indices,]))\n    \n    if (LargeSample== TRUE)\n    {\n      t2<-apply( matrix(B2(ag1, ag2), nrow=n_not_obs , byrow=T), 1, sum)\n    }else\n    {\n      t2<-apply( matrix(apply(cbind(ag1,ag2),1, function(x){B(x[1],x[2])}), nrow=n_not_obs , byrow=T), 1, sum) \n    }\n    p[not_obs_vec] <- 1/(1+ exp(-t1 + t2) ) \n    p_tilde[c_Indices]<-rep( p[not_obs_vec], each=J) \n    P_tilde<-diag(c(p_tilde))\n    \n    \n    #Marginal likelihood approximation <- E(Log_p(y,z,alpha,beta))- E(q(alpha, beta, z))\n    #-----------------------------------------------------------------------------------\n    Logp <- logp(c(alpha,beta), W=W_vb, X=X, Y=Y, P_tilde=P_tilde, p_tilde=p_tilde, p=p, alpha_0=alpha_0, SigmaInv_alpha_0=SigmaInv_alpha_0, beta_0=beta_0, SigmaInv_beta_0=SigmaInv_beta_0,Exp=1)\n    Logp <- Logp -const3  #E(Log_p(y,z,alpha,beta))\n    \n    #the E(q(alpha, beta, z)) part\n    #------------------------------\n    #E_log_pz <- sum(p[not_obs_vec]*log(p[not_obs_vec]/(1-p[not_obs_vec])) + log(1-p[not_obs_vec]))\n    E_log_pz <-sum(log(p[not_obs_vec]^p[not_obs_vec]) + log( (1-p[not_obs_vec])^(1-p[not_obs_vec]) ))\n    #E_log_p_alpha_beta <- -0.5*( const1 + log(det(Sigma_alpha)) + log(det(Sigma_beta)) )\n    E_log_p_alpha_beta <- -0.5*( const1 + determinant(Sigma_alpha, logarithm=T)$modulus[1] + determinant(Sigma_beta, logarithm=T)$modulus[1] )\n    \n    Log_ml <- Logp - E_log_p_alpha_beta[1] - E_log_pz\n    \n    diff_Log_ml <- abs(Log_ml-old_Log_ml)\n    old_Log_ml <- Log_ml\n    \n    cat(\"Iteration: \", its,\", Log_ml <- \", round(Log_ml,digits<-6), \", alpha <- \", round(alpha,digits<-3) , \", beta <- \", round(beta,digits<-3), \"\\n\")\n  }\n  #out<- rbind(cbind(alpha ,sqrt(diag(Sigma_alpha))), cbind(beta,sqrt(diag(Sigma_beta))) )\n  #list(alpha=alpha, beta=beta, Sigma_alpha=Sigma_alpha, Sigma_beta=Sigma_beta, occup_p=p, out=out, Log_ml=Log_ml)\n\n  list(alpha=alpha, beta=beta, Sigma_alpha=Sigma_alpha, Sigma_beta=Sigma_beta, occup_p=p, Log_mla=Log_ml)\n}\n",
    "created" : 1412005413295.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "132844976",
    "id" : "75E2E1CE",
    "lastKnownWriteTime" : 1411996466,
    "path" : "C:/Users/AllanClark/Dropbox/PhD/Year1/ISEC2014/OccupancyModel2/Package/vboccupancy/R/VB_siteoccupancy_Model2_vb_laplace_fast_adapted.R",
    "project_path" : "R/VB_siteoccupancy_Model2_vb_laplace_fast_adapted.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}